# Mirroring Augmentation + Training (AlexNet / DenseNet-121)

**Goal:** Recreate the *mirroring* experiments from the paper.  
This notebook:
- Loads a prepared base dataset (`png_OR`, `jpg_OR`, etc. — class-per-folder).
- Creates a mirrored set (horizontal, vertical, both) **and keeps originals**.
- (Optional) tiles augmented images into **4x** or **16x** to match `_4x` / `_16x`.
- Trains **from scratch** (no pretrained weights) with either **AlexNet** or **DenseNet-121**.
- Saves **history.csv**, **predict.csv**, **y_true.csv**, **labels.txt**.

## How to use (Colab)
1. (Optional) **Mount Drive** (already set in the code).
2. Set these variables in the “User Config” section:
   - `SOURCE_DIR`: e.g., `/content/drive/MyDrive/microlab-data/prepared/png_OR`
   - `AUG_NAME`: e.g., `M_16x` (will be created in `prepared/`)
   - `DO_TILE`: `True` to tile; set `TILE_FACTOR` to `4` or `16`
   - `MODEL_NAME`: `"alexnet"` or `"densenet121"`
   - Batch size / epochs / learning rate as in the paper
3. **Run all**. Outputs are stored under `microlab-outputs/<model>_mirror_<AUG_NAME>/`.

## Notes
- **No pretrained weights** are used (training from scratch).
- Plot outputs are limited to **accuracy** and **loss**.
- If you started from original DIBaS TIFFs, remember the paper’s manual note:
  - Remove empty files if present: `Listeria.monocytogenes_0023.tif`, `Micrococcus.spp_0021.tif`, `Micrococcus.spp_0023.tif`.
- The dataset must be class-per-folder (ImageNet-style).

# ================================================================
#  Mirroring Augmentation + Train (AlexNet or DenseNet-121)
#  --------------------------------------------------------------
#  - Starts from a prepared dataset folder with class subfolders.
#  - Creates an augmented dataset by mirroring:
#       horizontal, vertical, both (h+v), and keeps originals.
#  - (Optional) tile into 4x or 16x after augmentation to match paper.
#  - Trains selected model (from scratch), plots acc/loss, saves CSVs.
#
#  Outputs (OUT_DIR):
#    history.csv, predict.csv, y_true.csv, labels.txt
#
#  Author: YOUR NAME | License: MIT
# ================================================================

!nvidia-smi -L || true

import os, sys, math, time, random, shutil
from pathlib import Path

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

SEED = 123
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- Mount Drive (optional)
USE_DRIVE = True
if USE_DRIVE:
    from google.colab import drive
    drive.mount('/content/drive')

# =======================
# User Config (edit)
# =======================
BASE_DATA   = '/content/drive/MyDrive/microlab-data/prepared' if USE_DRIVE else '/content/microlab-data/prepared'
SOURCE_DIR  = f'{BASE_DATA}/png_OR'     # e.g., png_OR (recommended), jpg_OR, etc.
AUG_NAME    = 'M_16x'                    # name suffix for augmented set (e.g., M_4x, M_16x)
DO_TILE     = True                       # tile augmented images to 4x or 16x?
TILE_FACTOR = 16                         # 4 or 16 (used only if DO_TILE=True)

MODEL_NAME  = 'densenet121'              # 'alexnet' or 'densenet121' (both from scratch)
IMG_SIZE    = (224, 224) if MODEL_NAME=='densenet121' else (227, 227)

BATCH_SIZE  = 64                         # keep 64 for DenseNet; 128 ok for AlexNet on 4x/16x
EPOCHS      = 25                         # 25 for 4x/16x; 50 for OR in your paper
LR          = 0.001 if MODEL_NAME=='densenet121' else 0.0015

# Output directories
OUT_ROOT    = '/content/drive/MyDrive/microlab-outputs' if USE_DRIVE else '/content/outputs'
OUT_DIR     = f'{OUT_ROOT}/{MODEL_NAME}_mirror_{AUG_NAME}'
os.makedirs(OUT_DIR, exist_ok=True)

print("SOURCE_DIR:", SOURCE_DIR)
print("AUG_NAME  :", AUG_NAME)
print("MODEL     :", MODEL_NAME)
print("OUT_DIR   :", OUT_DIR)

# =======================
# Helpers
# =======================
def ensure_clean_dir(path):
    p = Path(path)
    if p.exists():
        shutil.rmtree(p)
    p.mkdir(parents=True, exist_ok=True)

def mirror_variants(img: Image.Image):
    # returns list of mirrored variants (h, v, hv) + original
    # keep all to match paper's M set (original + flips)
    h = ImageOps.mirror(img)      # horizontal flip (left-right)
    v = ImageOps.flip(img)        # vertical flip (top-bottom)
    hv = ImageOps.flip(h)         # both
    return [img, h, v, hv]

def save_augmented_set(src_dir, dst_dir, do_tile=False, tile_factor=4):
    src = Path(src_dir)
    dst = Path(dst_dir)
    ensure_clean_dir(dst)

    # iterate classes
    for cls_dir in sorted(p for p in src.iterdir() if p.is_dir()):
        (dst/cls_dir.name).mkdir(parents=True, exist_ok=True)
        print(f"[Augment] Class: {cls_dir.name}")

        for img_path in sorted(cls_dir.glob('*.jpg')) + sorted(cls_dir.glob('*.png')):
            try:
                img = Image.open(img_path).convert('RGB')
            except Exception as e:
                print(f"Skip unreadable: {img_path} ({e})")
                continue

            variants = mirror_variants(img)

            # save variants
            for idx, im in enumerate(variants):
                base = img_path.stem
                out_name = f"{base}_m{idx}.jpg"
                out_path = dst/cls_dir.name/out_name

                if do_tile:
                    # tile into 4 or 16 equal parts
                    w, h = im.size
                    tx = 2 if tile_factor==4 else 4
                    ty = 2 if tile_factor==4 else 4
                    tile_w = w // tx
                    tile_h = h // ty
                    for r in range(ty):
                        for c in range(tx):
                            box = (c*tile_w, r*tile_h, (c+1)*tile_w, (r+1)*tile_h)
                            im.crop(box).save(dst/cls_dir.name/f"{base}_m{idx}_{r}_{c}.jpg", quality=95)
                else:
                    im.save(out_path, quality=95)

# =======================
# Build augmented dataset
# =======================
AUG_DIR = f"{BASE_DATA}/{AUG_NAME}"
print("Building augmented dataset at:", AUG_DIR)
save_augmented_set(SOURCE_DIR, AUG_DIR, DO_TILE, TILE_FACTOR)

# =======================
# Load dataset (80/20)
# =======================
train_ds = tf.keras.utils.image_dataset_from_directory(
    AUG_DIR, validation_split=0.2, subset='training', seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH_SIZE, crop_to_aspect_ratio=False
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    AUG_DIR, validation_split=0.2, subset='validation', seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH_SIZE, crop_to_aspect_ratio=False
)

class_names = train_ds.class_names
num_classes = len(class_names)
with open(os.path.join(OUT_DIR, 'labels.txt'), 'w') as f:
    for c in class_names: f.write(c+'\n')
print("Classes:", num_classes)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)

# quick viz
plt.figure(figsize=(9,9))
for images, labels in train_ds.take(1):
    for i in range(min(9, images.shape[0])):
        ax = plt.subplot(3,3,i+1)
        plt.imshow(images[i].numpy().astype('uint8'))
        plt.title(class_names[int(labels[i])], fontsize=8)
        plt.axis('off')
plt.tight_layout(); plt.show()

# =======================
# Models from scratch
# =======================
def build_alexnet(input_shape=(227,227,3), num_classes=33, lr=0.0015):
    m = keras.Sequential([
        layers.Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
        layers.Conv2D(256, (5,5), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
        layers.Conv2D(384, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(384, (1,1), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(256, (1,1), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
        layers.Flatten(),
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)
    m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return m

def build_densenet121_from_scratch(input_shape=(224,224,3), num_classes=33, lr=0.001):
    base = tf.keras.applications.DenseNet121(include_top=False, weights=None, input_shape=input_shape)
    inp = keras.Input(shape=input_shape)
    x = base(inp, training=True)
    x = layers.GlobalAveragePooling2D()(x)
    out = layers.Dense(num_classes, activation='softmax')(x)
    m = keras.Model(inp, out)
    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)
    m.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return m

if MODEL_NAME == 'alexnet':
    model = build_alexnet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=num_classes, lr=LR)
else:
    model = build_densenet121_from_scratch(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=num_classes, lr=LR)

model.summary()

# =======================
# Train
# =======================
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=1)

print("\nEvaluate TRAIN/VAL:")
tr_loss, tr_acc = model.evaluate(train_ds, verbose=0)
vl_loss, vl_acc = model.evaluate(val_ds, verbose=0)
print(f"Train acc={tr_acc:.4f}  Val acc={vl_acc:.4f}")

# =======================
# Save outputs
# =======================
pred_probs = model.predict(val_ds, verbose=1)
# y_true
y_true = np.concatenate([y for _, y in val_ds.as_numpy_iterator()], axis=0)

np.savetxt(os.path.join(OUT_DIR, 'predict.csv'), pred_probs, delimiter=',')
np.savetxt(os.path.join(OUT_DIR, 'y_true.csv'), y_true, delimiter=',')

import pandas as pd
pd.DataFrame.from_dict(history.history).to_csv(os.path.join(OUT_DIR, 'history.csv'), index=False)

print("Saved to", OUT_DIR)

# =======================
# Plots
# =======================
plt.figure(figsize=(7,5))
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy'); plt.ylabel('Accuracy'); plt.xlabel('Epoch'); plt.legend(); plt.grid(alpha=.3)
plt.tight_layout(); plt.show()

plt.figure(figsize=(7,5))
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss'); plt.ylabel('Loss'); plt.xlabel('Epoch'); plt.legend(); plt.grid(alpha=.3)
plt.tight_layout(); plt.show()
