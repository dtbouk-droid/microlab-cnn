# ================================================================
#  Rotation Augmentation + Train (AlexNet or DenseNet-121)
#  --------------------------------------------------------------
#  MODE: 'fixed' (90,180,270) or 'random' (0..90 deg)
#  Fills borders with reflection (no black corners).
#  Optional tiling to 4x / 16x after augmentation.
#
#  Outputs: history.csv, predict.csv, y_true.csv, labels.txt
# ================================================================

!nvidia-smi -L || true

import os, sys, math, time, random, shutil
from pathlib import Path

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from PIL import Image
import cv2
import matplotlib.pyplot as plt

SEED = 123
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

USE_DRIVE = True
if USE_DRIVE:
    from google.colab import drive
    drive.mount('/content/drive')

# =======================
# User Config (edit)
# =======================
BASE_DATA   = '/content/drive/MyDrive/microlab-data/prepared' if USE_DRIVE else '/content/microlab-data/prepared'
SOURCE_DIR  = f'{BASE_DATA}/png_OR'      # recommended base for augmentation
AUG_NAME    = 'R_16x'                    # e.g., R_4x / R_16x / A_16x in paper (A=Random)
MODE        = 'fixed'                    # 'fixed' or 'random'
DO_TILE     = True
TILE_FACTOR = 16                         # 4 or 16

MODEL_NAME  = 'densenet121'              # 'alexnet' or 'densenet121'
IMG_SIZE    = (224, 224) if MODEL_NAME=='densenet121' else (227, 227)
BATCH_SIZE  = 64
EPOCHS      = 25
LR          = 0.001 if MODEL_NAME=='densenet121' else 0.0015

OUT_ROOT    = '/content/drive/MyDrive/microlab-outputs' if USE_DRIVE else '/content/outputs'
OUT_DIR     = f'{OUT_ROOT}/{MODEL_NAME}_rotation_{AUG_NAME}_{MODE}'
os.makedirs(OUT_DIR, exist_ok=True)

print("SOURCE_DIR:", SOURCE_DIR)
print("AUG_NAME  :", AUG_NAME, "| MODE:", MODE)
print("MODEL     :", MODEL_NAME)
print("OUT_DIR   :", OUT_DIR)

def ensure_clean_dir(path):
    p = Path(path)
    if p.exists(): shutil.rmtree(p)
    p.mkdir(parents=True, exist_ok=True)

def pil_to_cv(img):
    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

def cv_to_pil(img):
    return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

def rotate_fixed(img_pil):
    # returns original + 90 + 180 + 270
    img_cv = pil_to_cv(img_pil)
    h, w = img_cv.shape[:2]
    center = (w//2, h//2)
    out = [img_pil]
    for angle in [90, 180, 270]:
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        rot = cv2.warpAffine(img_cv, M, (w, h), flags=cv2.INTER_LINEAR,
                             borderMode=cv2.BORDER_REFLECT_101)
        out.append(cv_to_pil(rot))
    return out

def rotate_random(img_pil, max_deg=90):
    # single random rotation in [0,max_deg], reflect borders
    angle = random.uniform(0, max_deg)
    img_cv = pil_to_cv(img_pil)
    h, w = img_cv.shape[:2]
    center = (w//2, h//2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rot = cv2.warpAffine(img_cv, M, (w, h), flags=cv2.INTER_LINEAR,
                         borderMode=cv2.BORDER_REFLECT_101)
    return [img_pil, cv_to_pil(rot)]  # keep original + one random

def save_augmented_set(src_dir, dst_dir, mode='fixed', do_tile=False, tile_factor=4):
    src = Path(src_dir); dst = Path(dst_dir)
    ensure_clean_dir(dst)

    for cls_dir in sorted(p for p in src.iterdir() if p.is_dir()):
        (dst/cls_dir.name).mkdir(parents=True, exist_ok=True)
        print(f"[Augment|{mode}] Class:", cls_dir.name)

        for img_path in sorted(cls_dir.glob('*.jpg')) + sorted(cls_dir.glob('*.png')):
            try:
                img = Image.open(img_path).convert('RGB')
            except Exception as e:
                print("Skip:", img_path, e); continue

            if mode == 'fixed':
                variants = rotate_fixed(img)
            else:
                variants = rotate_random(img, 90)

            base = img_path.stem
            for idx, im in enumerate(variants):
                if do_tile:
                    w, h = im.size
                    tx = 2 if tile_factor==4 else 4
                    ty = 2 if tile_factor==4 else 4
                    tile_w = w // tx; tile_h = h // ty
                    for r in range(ty):
                        for c in range(tx):
                            box = (c*tile_w, r*tile_h, (c+1)*tile_w, (r+1)*tile_h)
                            im.crop(box).save(dst/cls_dir.name/f"{base}_r{idx}_{r}_{c}.jpg", quality=95)
                else:
                    im.save(dst/cls_dir.name/f"{base}_r{idx}.jpg", quality=95)

AUG_DIR = f"{BASE_DATA}/{AUG_NAME}"
print("Building augmented dataset at:", AUG_DIR)
save_augmented_set(SOURCE_DIR, AUG_DIR, MODE, DO_TILE, TILE_FACTOR)

# ---- Load dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
    AUG_DIR, validation_split=0.2, subset='training', seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH_SIZE
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    AUG_DIR, validation_split=0.2, subset='validation', seed=SEED,
    image_size=IMG_SIZE, batch_size=BATCH_SIZE
)

class_names = train_ds.class_names; num_classes = len(class_names)
with open(os.path.join(OUT_DIR, 'labels.txt'), 'w') as f:
    for c in class_names: f.write(c+'\n')
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(AUTOTUNE)
val_ds   = val_ds.cache().prefetch(AUTOTUNE)

# quick viz
plt.figure(figsize=(9,9))
for images, labels in train_ds.take(1):
    for i in range(min(9, images.shape[0])):
        ax = plt.subplot(3,3,i+1)
        plt.imshow(images[i].numpy().astype('uint8'))
        plt.title(class_names[int(labels[i])], fontsize=8)
        plt.axis('off')
plt.tight_layout(); plt.show()

# ---- Models
def build_alexnet(input_shape=(227,227,3), num_classes=33, lr=0.0015):
    m = keras.Sequential([
        layers.Conv2D(96,(11,11),strides=(4,4),activation='relu',input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPool2D((3,3),(2,2)),
        layers.Conv2D(256,(5,5),padding='same',activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPool2D((3,3),(2,2)),
        layers.Conv2D(384,(3,3),padding='same',activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(384,(1,1),padding='same',activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(256,(1,1),padding='same',activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPool2D((3,3),(2,2)),
        layers.Flatten(),
        layers.Dense(4096,activation='relu'), layers.Dropout(0.5),
        layers.Dense(4096,activation='relu'), layers.Dropout(0.5),
        layers.Dense(num_classes,activation='softmax')
    ])
    m.compile(optimizer=tf.keras.optimizers.SGD(LR, momentum=0.9),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return m

def build_densenet121_from_scratch(input_shape=(224,224,3), num_classes=33, lr=0.001):
    base = tf.keras.applications.DenseNet121(include_top=False, weights=None, input_shape=input_shape)
    inp = keras.Input(shape=input_shape)
    x = base(inp, training=True)
    x = layers.GlobalAveragePooling2D()(x)
    out= layers.Dense(num_classes, activation='softmax')(x)
    m = keras.Model(inp, out)
    m.compile(optimizer=tf.keras.optimizers.SGD(lr, momentum=0.9),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return m

model = build_alexnet((IMG_SIZE[0],IMG_SIZE[1],3), num_classes, LR) if MODEL_NAME=='alexnet' \
        else build_densenet121_from_scratch((IMG_SIZE[0],IMG_SIZE[1],3), num_classes, LR)
model.summary()

# ---- Train
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=1)

# ---- Save outputs
pred_probs = model.predict(val_ds, verbose=1)
y_true = np.concatenate([y for _, y in val_ds.as_numpy_iterator()], axis=0)
np.savetxt(os.path.join(OUT_DIR, 'predict.csv'), pred_probs, delimiter=',')
np.savetxt(os.path.join(OUT_DIR, 'y_true.csv'), y_true, delimiter=',')

import pandas as pd
pd.DataFrame.from_dict(history.history).to_csv(os.path.join(OUT_DIR, 'history.csv'), index=False)
with open(os.path.join(OUT_DIR, 'labels.txt'),'w') as f:
    for c in class_names: f.write(c+'\n')

# ---- Plots
plt.figure(figsize=(7,5))
plt.plot(history.history['accuracy']); plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy'); plt.ylabel('Accuracy'); plt.xlabel('Epoch'); plt.legend(['Train','Validation'])
plt.grid(alpha=.3); plt.tight_layout(); plt.show()

plt.figure(figsize=(7,5))
plt.plot(history.history['loss']); plt.plot(history.history['val_loss'])
plt.title('Model Loss'); plt.ylabel('Loss'); plt.xlabel('Epoch'); plt.legend(['Train','Validation'])
plt.grid(alpha=.3); plt.tight_layout(); plt.show()
